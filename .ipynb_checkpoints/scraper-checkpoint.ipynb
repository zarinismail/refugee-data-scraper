{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bec29e4-9d0c-450d-b432-cfb45c529040",
   "metadata": {},
   "source": [
    "# UNHCR Refugee Applications Data Scraper\n",
    "This scraper grabs entity names, new refugee applications (to leave) for each of those entities, application acceptances (recognitions or protections), application rejections, and pending decisions. The UNHCR has data for 229 countries/entities.\n",
    "\n",
    "Data are retrieved from this site: [Refugee Data Finder](https://www.unhcr.org/refugee-statistics/data-summaries?data_summaries%5Bregion%5D=&data_summaries%5Bcountry%5D=&data_summaries%5BwithinFrom%5D=from&data_summaries%5Bview%5D=asylum_applications_decisions&data_summaries%5Byear%5D=2024&data_summaries%5BpopType%5D=FDP&data_summaries%5B_mode%5D=country&data_summaries%5B_token%5D=6987cded38eae.zI1K2yKKVqlikInn8U5IcnnnT9iyimmU85vCiq_BvfE.jcsIkhanJ-gx1POrwAMZO0CiKeji2ii5gNKY4P-4y8S-_3uuEv4Tnw3RzA&data_summaries%5Bsubmit%5D=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799de96d-9c01-4b18-bda4-816ceb7d0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36'}\n",
    "\n",
    "# Main summary page to retrieve URLs\n",
    "url = \"https://www.unhcr.org/refugee-statistics/data-summaries?data_summaries%5Bregion%5D=&data_summaries%5Bcountry%5D=&data_summaries%5BwithinFrom%5D=from&data_summaries%5Bview%5D=asylum_applications_decisions&data_summaries%5Byear%5D=2024&data_summaries%5BpopType%5D=FDP&data_summaries%5B_mode%5D=country&data_summaries%5B_token%5D=6987cded38eae.zI1K2yKKVqlikInn8U5IcnnnT9iyimmU85vCiq_BvfE.jcsIkhanJ-gx1POrwAMZO0CiKeji2ii5gNKY4P-4y8S-_3uuEv4Tnw3RzA&data_summaries%5Bsubmit%5D=\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d39bd-4d45-48f0-a7d8-b4600aaf983f",
   "metadata": {},
   "source": [
    "## `get_urls(main_url)`\n",
    "A function that retrieves the option values of countries from a dropdown menu on the main page, appends them in the appropriate position of the main URL to create the country URLs, and puts all country URLs into a list that is returned. \n",
    "\n",
    "To access a country's page, the user must select it from the dropdown menu. The country URL is the user's selection. The option value is used in the URL to specify which country is selected from the dropdown menu. The structure of the URL for each country's data summary page is nearly identical to the main page's URL except that the country's option value is logically inserted somewhere in the URL. The list that is returned through this function is to be looped through to access each country's URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743419e4-0712-477d-abd8-d992c1d7001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(main_url):\n",
    "    page = requests.get(main_url, headers=hdr)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    url_list = []\n",
    "    \n",
    "    # Get dropdown menu\n",
    "    dropdown_menu = soup.find(id=\"data_summaries_country\")\n",
    "    # Get options in menu (every option is a country/entity)\n",
    "    options = dropdown_menu.find_all(\"option\")\n",
    "    time.sleep(1)\n",
    "    # Get the value for each option and append to urls list\n",
    "    for option in options:\n",
    "        time.sleep(1)\n",
    "        entity_value = option.attrs['value']\n",
    "        if entity_value != \"\":\n",
    "            url = \"https://www.unhcr.org/refugee-statistics/data-summaries?data_summaries%5Bregion%5D=&data_summaries%5Bcountry%5D=\" + entity_value + \"&data_summaries%5BwithinFrom%5D=from&data_summaries%5Bview%5D=asylum_applications_decisions&data_summaries%5Byear%5D=2024&data_summaries%5BpopType%5D=FDP&data_summaries%5B_mode%5D=country&data_summaries%5B_token%5D=6987cded38eae.zI1K2yKKVqlikInn8U5IcnnnT9iyimmU85vCiq_BvfE.jcsIkhanJ-gx1POrwAMZO0CiKeji2ii5gNKY4P-4y8S-_3uuEv4Tnw3RzA&data_summaries%5Bsubmit%5D=\"\n",
    "            url_list.append(url)\n",
    "\n",
    "    return url_list\n",
    "\n",
    "# Call get_urls()\n",
    "url_list = get_urls(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410200df-f66b-49db-98ac-506cd0c2c3d3",
   "metadata": {},
   "source": [
    "## `get_info(page_url)`\n",
    "A function that retrieves the entity name and four data points from a summary page and returns them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90deb0b4-bc10-4ae4-b4d1-82441a74f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(page_url):\n",
    "    page = requests.get(page_url, headers=hdr)\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    data_list = []\n",
    "\n",
    "    summary = soup.find(id=\"data_summaries_content\")\n",
    "    country_hed = summary.find(\"h2\")\n",
    "    # Clean country heading\n",
    "    country = country_hed.text.strip()\n",
    "    # Find first space in the country heading\n",
    "    trim = country.find(\" \")\n",
    "    # Trim off \"Country: \" in country heading\n",
    "    country = country[trim+1:]\n",
    "    # Append country name to list\n",
    "    data_list.append(country)\n",
    "    \n",
    "    # Grab four data points\n",
    "    info_figures = summary.find_all(\"h4\")\n",
    "    \n",
    "    for fig_text in info_figures:\n",
    "        # Clean string\n",
    "        fig_text = fig_text.text.strip()\n",
    "        if \",\" in fig_text:\n",
    "            fig_text = fig_text.replace(\",\",\"\")\n",
    "        data_list.append(fig_text)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58abfe-7b05-4a40-bc5b-f858c6b27fbb",
   "metadata": {},
   "source": [
    "## `write_csv(url_list)`\n",
    "A function that writes a list of data points (returned through the `get_info()` function) in each row for every URL in a list of URLs (returned through the `get_urls()` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6bbe3a9-4c69-4ea5-8eb2-b6abe050e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(url_list):\n",
    "    csvfile = open('refugee_apps.csv', 'w', newline='', encoding='utf-8')\n",
    "    c = csv.writer(csvfile)\n",
    "    \n",
    "    # Write column headings in a row\n",
    "    c.writerow(['entity', 'new applications', 'acceptances', 'rejections', 'pending'])\n",
    "\n",
    "    # Loop through each entity's URL to retrieve info and write into a row\n",
    "    for entity_url in url_list:\n",
    "        entity_data = get_info(entity_url)\n",
    "        time.sleep(1)\n",
    "        c.writerow(entity_data)\n",
    "    \n",
    "    # Close file\n",
    "    csvfile.close()\n",
    "    \n",
    "    # Return None to bypass potential error\n",
    "    return None\n",
    "\n",
    "# Run function to create CSV file\n",
    "write_csv(url_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
